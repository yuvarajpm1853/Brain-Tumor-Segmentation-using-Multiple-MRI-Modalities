{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nimport keras\nfrom matplotlib import pyplot as plt\nimport glob\nimport random","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\nimport numpy as np\n\n\ndef load_img(img_dir, img_list):\n    images=[]\n    for i, image_name in enumerate(img_list):    \n        if (image_name.split('.')[1] == 'npy'):\n            \n            image = np.load(img_dir+image_name)\n                      \n            images.append(image)\n    images = np.array(images)\n    \n    return(images)\n\n\n\n\ndef imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):\n\n    L = len(img_list)\n\n    #keras needs the generator infinite, so we will use while true  \n    while True:\n\n        batch_start = 0\n        batch_end = batch_size\n\n        while batch_start < L:\n            limit = min(batch_end, L)\n                       \n            X = load_img(img_dir, img_list[batch_start:limit])\n            Y = load_img(mask_dir, mask_list[batch_start:limit])\n\n            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     \n\n            batch_start += batch_size   \n            batch_end += batch_size","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_img_dir = \"BraTS2020_TrainingData/input_data_128/train/images/\"\ntrain_mask_dir = \"BraTS2020_TrainingData/input_data_128/train/masks/\"\n\nval_img_dir = \"BraTS2020_TrainingData/input_data_128/val/images/\"\nval_mask_dir = \"BraTS2020_TrainingData/input_data_128/val/masks/\"\n\ntrain_img_list=os.listdir(train_img_dir)\ntrain_mask_list = os.listdir(train_mask_dir)\n\nval_img_list=os.listdir(val_img_dir)\nval_mask_list = os.listdir(val_mask_dir)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 2\n\ntrain_img_datagen = imageLoader(train_img_dir, train_img_list, \n                                train_mask_dir, train_mask_list, batch_size)\n\nval_img_datagen = imageLoader(val_img_dir, val_img_list, \n                                val_mask_dir, val_mask_list, batch_size)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, msk = train_img_datagen.__next__()\n\nimg_num = random.randint(0,img.shape[0]-1)\ntest_img=img[img_num]\ntest_mask=msk[img_num]\ntest_mask=np.argmax(test_mask, axis=3)\n\nn_slice=random.randint(0, test_mask.shape[2])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\n\nplt.subplot(221)\nplt.imshow(test_img[:,:,n_slice, 0], cmap='gray')\nplt.title('Image flair')\nplt.subplot(222)\nplt.imshow(test_img[:,:,n_slice, 1], cmap='gray')\nplt.title('Image t1ce')\nplt.subplot(223)\nplt.imshow(test_img[:,:,n_slice, 2], cmap='gray')\nplt.title('Image t2')\nplt.subplot(224)\nplt.imshow(test_mask[:,:,n_slice])\nplt.title('Mask')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model train","metadata":{}},{"cell_type":"code","source":"wt0, wt1, wt2, wt3 = 0.25,0.25,0.25,0.25\nLR = 0.0001\noptim = keras.optimizers.Adam(LR)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_loss(y_true, y_pred):\n    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1, 2, 3))\n    denominator = tf.reduce_sum(y_true + y_pred, axis=(1, 2, 3))\n    return 1 - tf.reduce_mean(numerator / denominator)\n\n\ndef categorical_focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0):\n    epsilon = 1e-7\n    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n    loss = -tf.reduce_sum(alpha * tf.pow(1 - y_pred, gamma) * y_true * tf.math.log(y_pred), axis=-1)\n    return tf.reduce_mean(loss)\n\n\ndef total_loss(y_true, y_pred):\n    wt0, wt1, wt2, wt3 = 0.25, 0.25, 0.25, 0.25\n    dice = dice_loss(y_true, y_pred)\n    focal = categorical_focal_loss(y_true, y_pred)\n    return dice + focal\ndef accuracy(y_true, y_pred):\n    correct_predictions = tf.equal(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1))\n    return tf.reduce_mean(tf.cast(correct_predictions, tf.float32))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsteps_per_epoch = len(train_img_list)//batch_size\nval_steps_per_epoch = len(val_img_list)//batch_size\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom keras.models import Model\nfrom keras.layers import Input, Conv3D, MaxPooling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\nfrom keras.optimizers import Adam\nfrom keras.metrics import MeanIoU\n\nkernel_initializer =  'he_uniform' #Try others if you want\n\n\n################################################################\ndef simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS, num_classes):\n#Build the model\n    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS))\n    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n    s = inputs\n\n    #Contraction path\n    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(s)\n    c1 = Dropout(0.1)(c1)\n    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c1)\n    p1 = MaxPooling3D((2, 2, 2))(c1)\n    \n    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p1)\n    c2 = Dropout(0.1)(c2)\n    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c2)\n    p2 = MaxPooling3D((2, 2, 2))(c2)\n     \n    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p2)\n    c3 = Dropout(0.2)(c3)\n    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c3)\n    p3 = MaxPooling3D((2, 2, 2))(c3)\n     \n    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p3)\n    c4 = Dropout(0.2)(c4)\n    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c4)\n    p4 = MaxPooling3D(pool_size=(2, 2, 2))(c4)\n     \n    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p4)\n    c5 = Dropout(0.3)(c5)\n    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c5)\n    \n    #Expansive path \n    u6 = Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u6)\n    c6 = Dropout(0.2)(c6)\n    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c6)\n     \n    u7 = Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u7)\n    c7 = Dropout(0.2)(c7)\n    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c7)\n     \n    u8 = Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u8)\n    c8 = Dropout(0.1)(c8)\n    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c8)\n     \n    u9 = Conv3DTranspose(16, (2, 2, 2), strides=(2, 2, 2), padding='same')(c8)\n    u9 = concatenate([u9, c1])\n    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u9)\n    c9 = Dropout(0.1)(c9)\n    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c9)\n     \n    outputs = Conv3D(num_classes, (1, 1, 1), activation='softmax')(c9)\n     \n    model = Model(inputs=[inputs], outputs=[outputs])\n    #compile model outside of this function to make it flexible. \n    model.summary()\n    \n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = simple_unet_model(IMG_HEIGHT=128, \n                          IMG_WIDTH=128, \n                          IMG_DEPTH=128, \n                          IMG_CHANNELS=3, \n                          num_classes=4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = optim, loss=total_loss, metrics=[accuracy, tf.keras.metrics.MeanIoU(num_classes=4)])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nimport keras.backend as K\nfrom keras.callbacks import CSVLogger\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# callback","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nhistory=model.fit(train_img_datagen,\n          steps_per_epoch=steps_per_epoch,\n          epochs=100,\n          verbose=1,\n          validation_data=val_img_datagen,\n          validation_steps=val_steps_per_epoch,\n          )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('brats_3d.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GRAPH","metadata":{}},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.plot(epochs, acc, 'y', label='Training accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MOU","metadata":{}},{"cell_type":"code","source":"\nfrom keras.metrics import MeanIoU\n\nbatch_size=8 #Check IoU for a batch of images\ntest_img_datagen = imageLoader(val_img_dir, val_img_list, \n                                val_mask_dir, val_mask_list, batch_size)\n\n#Verify generator.... In python 3 next() is renamed as __next__()\ntest_image_batch, test_mask_batch = test_img_datagen.__next__()\n\ntest_mask_batch_argmax = np.argmax(test_mask_batch, axis=4)\ntest_pred_batch = model.predict(test_image_batch)\ntest_pred_batch_argmax = np.argmax(test_pred_batch, axis=4)\n\nn_classes = 4\nIOU_keras = MeanIoU(num_classes=n_classes)  \nIOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\nprint(\"Mean IoU =\", IOU_keras.result().numpy())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREDICT","metadata":{}},{"cell_type":"code","source":"\nimg_num = 82\n\ntest_img = np.load(\"BraTS2020_TrainingData/input_data_128/val/images/image_\"+str(img_num)+\".npy\")\n\ntest_mask = np.load(\"BraTS2020_TrainingData/input_data_128/val/masks/mask_\"+str(img_num)+\".npy\")\ntest_mask_argmax=np.argmax(test_mask, axis=3)\n\ntest_img_input = np.expand_dims(test_img, axis=0)\ntest_prediction = my_model.predict(test_img_input)\ntest_prediction_argmax=np.argmax(test_prediction, axis=4)[0,:,:,:]\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot individual slices from test predictions for verification\nfrom matplotlib import pyplot as plt\nimport random\n\n#n_slice=random.randint(0, test_prediction_argmax.shape[2])\nn_slice = 55\nplt.figure(figsize=(12, 8))\nplt.subplot(231)\nplt.title('Testing Image')\nplt.imshow(test_img[:,:,n_slice,1], cmap='gray')\nplt.subplot(232)\nplt.title('Testing Label')\nplt.imshow(test_mask_argmax[:,:,n_slice])\nplt.subplot(233)\nplt.title('Prediction on test image')\nplt.imshow(test_prediction_argmax[:,:, n_slice])\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]}]}